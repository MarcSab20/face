"""
Routes pour la g√©n√©ration de rapports intelligents narratifs
VERSION CORRIG√âE - SANS ERREUR F-STRING
Priorit√© absolue : Groq ‚Üí Gemini ‚Üí Ollama
"""

from fastapi import APIRouter, HTTPException, Query, Depends
from typing import List, Optional
from datetime import datetime, timedelta
import logging
from sqlalchemy.orm import Session
from app.database import get_db
from app.models import Keyword, Mention
from app.unified_ai_service import UnifiedAIService
import os
import json

router = APIRouter(prefix="/api/reports", tags=["Reports"])
logger = logging.getLogger(__name__)


def get_prioritized_ai_service() -> UnifiedAIService:
    """
    Initialise le service IA avec PRIORISATION ABSOLUE Groq ‚Üí Gemini ‚Üí Ollama
    """
    groq_key = os.getenv("GROQ_API_KEY")
    gemini_key = os.getenv("GEMINI_API_KEY")
    
    logger.info("üîç Configuration des services IA:")
    logger.info(f"   - Groq: {'‚úÖ Configur√©' if groq_key else '‚ùå Manquant'}")
    logger.info(f"   - Gemini: {'‚úÖ Configur√©' if gemini_key else '‚ùå Manquant'}")
    
    if not groq_key and not gemini_key:
        logger.error("‚ùå CRITIQUE: Aucune API externe configur√©e!")
        raise HTTPException(
            status_code=503,
            detail="Aucune API IA externe configur√©e. Veuillez configurer GROQ_API_KEY ou GEMINI_API_KEY"
        )
    
    service = UnifiedAIService(
        groq_api_key=groq_key,
        gemini_api_key=gemini_key,
        ollama_host=os.getenv("OLLAMA_HOST", "http://ollama:11434"),
        ollama_model=os.getenv("OLLAMA_DEFAULT_MODEL", "gemma:2b")
    )
    
    return service


def filter_relevant_content(mentions: List[Mention], context_keywords: List[str]) -> List[Mention]:
    """
    Filtre intelligent des mentions pertinentes
    """
    relevant_mentions = []
    
    for mention in mentions:
        combined_text = " ".join(filter(None, [
            mention.title or "",
            mention.content or "",
            mention.author or ""
        ])).lower()
        
        # V√©rifier pertinence
        is_relevant = any(kw.lower() in combined_text for kw in context_keywords)
        
        # √âliminer contenus trop courts (spam)
        if is_relevant and len(combined_text) > 50:
            relevant_mentions.append(mention)
    
    logger.info(f"üìä Filtrage: {len(mentions)} ‚Üí {len(relevant_mentions)} contenus pertinents")
    return relevant_mentions


def build_content_list(contents: List[dict], max_items: int = 15) -> str:
    """
    Construire une liste de contenus pour les prompts
    """
    items = []
    for c in contents[:max_items]:
        title = c.get("title", "Sans titre")[:150]
        items.append(f"‚Ä¢ {title}")
    
    return "\n".join(items)


def build_influencer_list(influencers: List[dict]) -> str:
    """
    Construire une liste d'influenceurs pour les prompts
    """
    items = []
    for i, inf in enumerate(influencers[:5], 1):
        author = inf.get("author", "Inconnu")
        content_samples = inf.get("content", [])
        sample_titles = [c.get("title", "")[:60] for c in content_samples[:2]]
        sample_text = ", ".join(sample_titles)
        items.append(f"{i}. {author} - Exemples d'interventions : {sample_text}")
    
    return "\n".join(items)


async def generate_narrative_pure(
    ai_service: UnifiedAIService,
    section_name: str,
    data: dict,
    context: str
) -> str:
    """
    G√©n√®re une section PUREMENT NARRATIVE sans aucune statistique
    Force l'utilisation de Groq ou Gemini
    """
    logger.info(f"üé® G√©n√©ration narrative: {section_name}")
    
    # Construire les contenus format√©s AVANT les f-strings
    if section_name == "summary":
        content_list = build_content_list(data.get('content', []))
        prompt = f"""Contexte de surveillance : {context}

Vous analysez des discussions publiques collect√©es sur ce sujet.

CONTENUS COLLECT√âS (extraits repr√©sentatifs) :
{content_list}

INSTRUCTION ABSOLUE :
R√©digez un r√©sum√© narratif en 3-4 paragraphes fluides qui raconte ce qui se dit dans ces discussions.

R√àGLES STRICTES :
- R√©digez UNIQUEMENT en paragraphes narratifs fluides
- INTERDICTION ABSOLUE de listes √† puces, num√©ros, bullet points
- INTERDICTION ABSOLUE de mentionner des chiffres, pourcentages, statistiques
- D√©crivez qualitativement les tendances observ√©es
- Racontez les th√®mes principaux comme une histoire
- Ton professionnel, factuel, style briefing minist√©riel
- Ignorez les contenus non pertinents au contexte

R√©ponse (paragraphes narratifs uniquement) :"""

    elif section_name == "sentiment":
        positive_list = build_content_list(data.get('positive', []), 5)
        negative_list = build_content_list(data.get('negative', []), 5)
        neutral_list = build_content_list(data.get('neutral', []), 5)
        
        prompt = f"""Contexte : {context}

EXEMPLES DE CONTENUS POSITIFS :
{positive_list}

EXEMPLES DE CONTENUS CRITIQUES :
{negative_list}

EXEMPLES DE CONTENUS NEUTRES :
{neutral_list}

INSTRUCTION ABSOLUE :
R√©digez une analyse narrative en 3-4 paragraphes sur les tonalit√©s et sentiments exprim√©s.

R√àGLES STRICTES :
- Paragraphes narratifs fluides UNIQUEMENT
- AUCUN chiffre, pourcentage, statistique
- D√©crivez qualitativement : "majoritairement", "une partie", "certains", etc.
- Racontez les √©motions et r√©actions observ√©es
- Ton professionnel et analytique

R√©ponse :"""

    elif section_name == "influencers":
        influencer_list = build_influencer_list(data.get('influencers', []))
        
        prompt = f"""Contexte : {context}

PRINCIPAUX ACTEURS IDENTIFI√âS :
{influencer_list}

INSTRUCTION ABSOLUE :
R√©digez une analyse narrative en 3-4 paragraphes sur les acteurs influents et leur r√¥le.

R√àGLES STRICTES :
- Paragraphes narratifs fluides UNIQUEMENT
- AUCUN chiffre ou statistique
- D√©crivez qualitativement leur influence et leur positionnement
- Racontez leur r√¥le dans les discussions
- Ton professionnel

R√©ponse :"""

    elif section_name == "themes":
        content_list = build_content_list(data.get('content', []), 20)
        
        prompt = f"""Contexte : {context}

CONTENUS √Ä FORT ENGAGEMENT :
{content_list}

INSTRUCTION ABSOLUE :
R√©digez une analyse narrative en 3-4 paragraphes sur les th√®mes principaux identifi√©s.

R√àGLES STRICTES :
- Paragraphes narratifs fluides UNIQUEMENT
- AUCUN chiffre ou statistique
- Identifiez et d√©crivez qualitativement les sujets r√©currents
- Racontez les pr√©occupations principales
- Ton professionnel

R√©ponse :"""

    elif section_name == "recommendations":
        prompt = f"""Contexte : {context}

Observations g√©n√©rales sur les discussions analys√©es.

INSTRUCTION ABSOLUE :
R√©digez 3-4 paragraphes de recommandations strat√©giques narratives.

R√àGLES STRICTES :
- Paragraphes narratifs fluides UNIQUEMENT
- AUCUN chiffre ou statistique
- Proposez des actions concr√®tes de mani√®re narrative
- Ton professionnel, style briefing minist√©riel
- Recommandations actionnables

R√©ponse :"""

    else:
        return f"Section {section_name} non configur√©e."
    
    # FORCER Groq ou Gemini
    try:
        # Priorit√© 1 : GROQ
        if os.getenv("GROQ_API_KEY"):
            logger.info("üöÄ Tentative avec Groq (priorit√© 1)")
            try:
                result = await ai_service.generate(
                    prompt=prompt,
                    max_tokens=1000,
                    temperature=0.2  # Factualit√© maximale
                )
                
                if result.get('success') and result.get('text'):
                    text = result['text'].strip()
                    if len(text) > 100:
                        logger.info(f"‚úÖ Section '{section_name}' g√©n√©r√©e avec Groq")
                        return text
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Groq a √©chou√©: {e}")
        
        # Priorit√© 2 : GEMINI
        if os.getenv("GEMINI_API_KEY"):
            logger.info("üåü Tentative avec Gemini (priorit√© 2)")
            try:
                result = await ai_service.generate(
                    prompt=prompt,
                    max_tokens=1000,
                    temperature=0.2
                )
                
                if result.get('success') and result.get('text'):
                    text = result['text'].strip()
                    if len(text) > 100:
                        logger.info(f"‚úÖ Section '{section_name}' g√©n√©r√©e avec Gemini")
                        return text
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Gemini a √©chou√©: {e}")
        
        # Dernier recours : Ollama (mais on pr√©f√®re √©viter)
        logger.warning("‚ö†Ô∏è Fallback vers Ollama (moins optimal)")
        result = await ai_service.generate(
            prompt=prompt,
            max_tokens=1000,
            temperature=0.2
        )
        
        if result.get('success') and result.get('text'):
            return result['text'].strip()
        
        raise Exception("Tous les services IA ont √©chou√©")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration section {section_name}: {str(e)}")
        return f"Impossible de g√©n√©rer cette section (erreur technique: {str(e)})"


@router.post("/generate-narrative")
async def generate_narrative_report(
    keyword_ids: List[int] = Query(..., description="Liste des IDs de mots-cl√©s"),
    period: str = Query("30d", description="P√©riode (7d, 14d, 30d, 90d)"),
    sections: List[str] = Query(
        ["summary", "sentiment", "influencers", "themes", "recommendations"],
        description="Sections √† g√©n√©rer"
    ),
    db: Session = Depends(get_db)
):
    """
    G√©n√®re un rapport narratif pur sans statistiques
    Priorit√© : Groq ‚Üí Gemini ‚Üí Ollama
    """
    try:
        logger.info(f"üìä G√©n√©ration rapport: keywords={keyword_ids}, period={period}")
        
        # === √âTAPE 1: R√©cup√©rer contexte ===
        keywords = db.query(Keyword).filter(Keyword.id.in_(keyword_ids)).all()
        
        if not keywords:
            raise HTTPException(status_code=404, detail="Aucun mot-cl√© trouv√©")
        
        keyword_texts = [kw.keyword for kw in keywords]
        context = f"Surveillance de l'opinion publique sur : {', '.join(keyword_texts)}"
        
        logger.info(f"üéØ Contexte: {context}")
        
        # === √âTAPE 2: R√©cup√©rer mentions ===
        period_days = int(period.replace('d', ''))
        start_date = datetime.now() - timedelta(days=period_days)
        
        mentions = db.query(Mention).filter(
            Mention.keyword_id.in_(keyword_ids),
            Mention.collected_at >= start_date
        ).all()
        
        logger.info(f"üì• {len(mentions)} mentions brutes collect√©es")
        
        if len(mentions) == 0:
            raise HTTPException(
                status_code=404,
                detail=f"Aucune mention trouv√©e pour la p√©riode de {period_days} jours"
            )
        
        # === √âTAPE 3: Filtrer contenus pertinents ===
        relevant_mentions = filter_relevant_content(mentions, keyword_texts)
        
        if len(relevant_mentions) == 0:
            raise HTTPException(
                status_code=404,
                detail="Aucun contenu pertinent apr√®s filtrage"
            )
        
        # === √âTAPE 4: Initialiser service IA ===
        ai_service = get_prioritized_ai_service()
        
        # === √âTAPE 5: Pr√©parer donn√©es pour chaque section ===
        sample_mentions = relevant_mentions[:100]  # Limiter √† 100 pour performance
        
        # Donn√©es r√©sum√©
        data_summary = {
            "content": [
                {
                    "title": m.title or "Sans titre",
                    "excerpt": (m.content or "")[:200]
                }
                for m in sample_mentions[:20]
            ]
        }
        
        # Donn√©es sentiment
        data_sentiment = {
            "positive": [
                {"title": m.title, "excerpt": (m.content or "")[:150]} 
                for m in sample_mentions if m.sentiment == "positive"
            ][:8],
            "negative": [
                {"title": m.title, "excerpt": (m.content or "")[:150]} 
                for m in sample_mentions if m.sentiment == "negative"
            ][:8],
            "neutral": [
                {"title": m.title, "excerpt": (m.content or "")[:150]} 
                for m in sample_mentions if m.sentiment == "neutral"
            ][:8]
        }
        
        # Donn√©es influenceurs
        from collections import Counter
        author_counts = Counter([m.author for m in sample_mentions if m.author and m.author != 'Unknown'])
        data_influencers = {
            "influencers": [
                {
                    "author": author,
                    "content": [
                        {"title": m.title}
                        for m in sample_mentions if m.author == author
                    ][:3]
                }
                for author, _ in author_counts.most_common(8)
            ]
        }
        
        # Donn√©es th√®mes (contenus √† fort engagement)
        sorted_mentions = sorted(
            sample_mentions,
            key=lambda m: getattr(m, 'engagement_score', 0) or 0,
            reverse=True
        )
        
        data_themes = {
            "content": [
                {
                    "title": m.title,
                    "excerpt": (m.content or "")[:200]
                }
                for m in sorted_mentions[:25]
            ]
        }
        
        # Donn√©es recommandations
        data_recommendations = {
            "context": context,
            "sample_concerns": [m.title for m in sorted_mentions[:10]]
        }
        
        # === √âTAPE 6: G√©n√©rer sections ===
        report_sections = {}
        
        section_data_map = {
            "summary": data_summary,
            "sentiment": data_sentiment,
            "influencers": data_influencers,
            "themes": data_themes,
            "recommendations": data_recommendations
        }
        
        for section in sections:
            if section in section_data_map:
                logger.info(f"üìù G√©n√©ration section: {section}")
                content = await generate_narrative_pure(
                    ai_service,
                    section,
                    section_data_map[section],
                    context
                )
                report_sections[section] = content
        
        # === √âTAPE 7: Compiler rapport final ===
        # Obtenir info sur service utilis√© (STRING pas OBJECT)
        available_services = ai_service.get_available_services()
        primary_service_label = available_services[0].get("label", "Inconnu") if available_services else "Inconnu"
        
        report = {
            "metadata": {
                "title": f"Rapport d'Analyse - {', '.join(keyword_texts)}",
                "generated_at": datetime.now().isoformat(),
                "period": f"{period_days} jours",
                "keywords": keyword_texts,
                "total_mentions_collected": len(mentions),
                "relevant_mentions_analyzed": len(relevant_mentions),
                "classification": "DOCUMENT DE TRAVAIL - DIFFUSION RESTREINTE",
                "ai_service_used": primary_service_label  # STRING pas OBJECT
            },
            "sections": report_sections,
            "context": context
        }
        
        logger.info(f"‚úÖ Rapport g√©n√©r√© avec succ√®s ({len(report_sections)} sections)")
        
        return report
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration rapport: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/test-ai-services")
async def test_ai_services():
    """
    Tester la disponibilit√© des services IA
    """
    try:
        ai_service = get_prioritized_ai_service()
        
        available = ai_service.get_available_services()
        
        # Test rapide
        test_result = await ai_service.generate(
            prompt="R√©ponds simplement 'Service fonctionnel' en un paragraphe.",
            max_tokens=50,
            temperature=0.1
        )
        
        return {
            "services_disponibles": [
                {
                    "nom": svc.get("label"),
                    "priorite": svc.get("priority")
                }
                for svc in available
            ],
            "service_primaire": available[0].get("label") if available else "Aucun",
            "test_generation": {
                "succes": test_result.get('success'),
                "service_utilise": test_result.get('service'),
                "reponse": test_result.get('text', '')[:100]
            }
        }
    except Exception as e:
        logger.error(f"Erreur test services IA: {e}")
        raise HTTPException(status_code=500, detail=str(e))