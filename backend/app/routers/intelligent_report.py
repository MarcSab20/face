"""
Routes pour la g√©n√©ration de rapports intelligents narratifs
VERSION CORRIG√âE - Priorisation Groq/Gemini
"""

from fastapi import APIRouter, HTTPException, Query
from fastapi import Depends
from typing import List, Optional
from datetime import datetime, timedelta
import logging
from sqlalchemy.orm import Session
from app.database import get_db
from app.models import Keyword, Mention
from app.unified_ai_service import UnifiedAIService
import os

router = APIRouter(prefix="/api/reports", tags=["Reports"])
logger = logging.getLogger(__name__)


def get_prioritized_ai_service() -> UnifiedAIService:
    """
    Initialise le service IA avec PRIORISATION ABSOLUE de Groq et Gemini
    """
    # R√©cup√©rer les cl√©s API depuis l'environnement
    groq_key = os.getenv("GROQ_API_KEY")
    gemini_key = os.getenv("GEMINI_API_KEY")
    
    logger.info("üîç V√©rification des cl√©s API disponibles:")
    logger.info(f"   - Groq API Key: {'‚úÖ Pr√©sente' if groq_key else '‚ùå Manquante'}")
    logger.info(f"   - Gemini API Key: {'‚úÖ Pr√©sente' if gemini_key else '‚ùå Manquante'}")
    
    # Cr√©er le service avec priorisation explicite
    service = UnifiedAIService(
        groq_api_key=groq_key,
        gemini_api_key=gemini_key,
        ollama_host=os.getenv("OLLAMA_HOST", "http://ollama:11434")
    )
    
    # V√©rifier les services disponibles
    available = service.get_available_services()
    logger.info(f"ü§ñ Services IA disponibles: {available}")
    
    if not groq_key and not gemini_key:
        logger.warning("‚ö†Ô∏è ATTENTION: Aucune cl√© API externe - utilisation d'Ollama uniquement")
    
    return service


def filter_relevant_content(mentions: List[Mention], context_keywords: List[str]) -> List[Mention]:
    """
    Filtre les mentions pour ne garder que celles qui sont r√©ellement pertinentes au contexte
    
    Args:
        mentions: Liste de toutes les mentions
        context_keywords: Mots-cl√©s du contexte de surveillance
    
    Returns:
        Liste filtr√©e de mentions pertinentes
    """
    relevant_mentions = []
    
    for mention in mentions:
        # Combiner tous les textes disponibles
        combined_text = " ".join(filter(None, [
            mention.title or "",
            mention.content or "",
            mention.author or ""
        ])).lower()
        
        # V√©rifier si au moins un mot-cl√© du contexte est pr√©sent
        is_relevant = any(kw.lower() in combined_text for kw in context_keywords)
        
        # √âliminer les contenus trop courts (probablement spam)
        if is_relevant and len(combined_text) > 50:
            relevant_mentions.append(mention)
    
    logger.info(f"üìä Filtrage: {len(mentions)} mentions ‚Üí {len(relevant_mentions)} pertinentes")
    
    return relevant_mentions


async def generate_narrative_section(
    ai_service: UnifiedAIService,
    section_name: str,
    data: dict,
    context: str
) -> str:
    """
    G√©n√®re une section narrative en utilisant l'IA avec PRIORISATION GROQ/GEMINI
    
    Args:
        ai_service: Service IA unifi√©
        section_name: Nom de la section
        data: Donn√©es √† analyser
        context: Contexte de surveillance
    
    Returns:
        Texte narratif g√©n√©r√©
    """
    logger.info(f"üé® G√©n√©ration section: {section_name}")
    
    # Construire le prompt sp√©cifique √† chaque section
    prompts = {
        "summary": f"""Contexte: {context}

Donn√©es: {len(data.get('content', []))} contenus les plus repr√©sentatifs collect√©s.

INSTRUCTION CRITIQUE:
R√©digez un r√©sum√© ex√©cutif professionnel de 2-4 paragraphes qui pr√©sente les tendances principales observ√©es dans les discussions.

R√àGLES STRICTES:
- R√©digez UNIQUEMENT en paragraphes fluides et coh√©rents
- N'utilisez JAMAIS de listes √† puces, num√©ros ou bullet points
- N'incluez AUCUN chiffre, statistique ou pourcentage
- Ton professionnel, factuel, neutre (style briefing minist√©riel)
- Ignorez compl√®tement les donn√©es non pertinentes au contexte
- Concentrez-vous sur les grandes tendances, pas les d√©tails

Exemples de contenus analys√©s (titres):
{chr(10).join([f'- {c.get("title", "Sans titre")[:100]}' for c in data.get('content', [])[:10]])}

R√©ponse:""",

        "sentiment": f"""Contexte: {context}

Donn√©es analys√©es:
- Contenus positifs: {len(data.get('positive', []))} exemples
- Contenus n√©gatifs: {len(data.get('negative', []))} exemples  
- Contenus neutres: {len(data.get('neutral', []))} exemples

INSTRUCTION CRITIQUE:
R√©digez une analyse narrative de 2-4 paragraphes sur les sentiments exprim√©s dans les discussions.

R√àGLES STRICTES:
- R√©digez UNIQUEMENT en paragraphes fluides et coh√©rents
- N'utilisez JAMAIS de listes √† puces, num√©ros ou bullet points
- N'incluez AUCUN chiffre, statistique ou pourcentage
- D√©crivez les tonalit√©s observ√©es de mani√®re qualitative
- Ignorez compl√®tement les donn√©es non pertinentes au contexte

Exemples de contenus positifs:
{chr(10).join([f'- {c.get("title", "")}' for c in data.get('positive', [])[:5]])}

Exemples de contenus n√©gatifs:
{chr(10).join([f'- {c.get("title", "")}' for c in data.get('negative', [])[:5]])}

R√©ponse:""",

        "influencers": f"""Contexte: {context}

Top 5 des auteurs les plus actifs:
{chr(10).join([f'{i+1}. {inf.get("author")} - Exemples: {", ".join([c.get("title", "")[:50] for c in inf.get("content", [])[:2]])}' 
              for i, inf in enumerate(data.get('influencers', [])[:5])])}

INSTRUCTION CRITIQUE:
R√©digez une analyse narrative de 2-4 paragraphes sur les acteurs cl√©s et leur influence dans les discussions.

R√àGLES STRICTES:
- R√©digez UNIQUEMENT en paragraphes fluides et coh√©rents
- N'utilisez JAMAIS de listes √† puces, num√©ros ou bullet points
- N'incluez AUCUN chiffre, statistique ou pourcentage
- D√©crivez les r√¥les et l'impact des acteurs de mani√®re qualitative
- Ignorez compl√®tement les donn√©es non pertinentes au contexte

R√©ponse:""",

        "themes": f"""Contexte: {context}

Principaux contenus √† fort engagement:
{chr(10).join([f'- {c.get("title", "Sans titre")[:100]}' for c in data.get('content', [])[:15]])}

INSTRUCTION CRITIQUE:
R√©digez une analyse narrative de 2-4 paragraphes sur les th√®mes principaux et les pr√©occupations identifi√©es.

R√àGLES STRICTES:
- R√©digez UNIQUEMENT en paragraphes fluides et coh√©rents
- N'utilisez JAMAIS de listes √† puces, num√©ros ou bullet points
- N'incluez AUCUN chiffre, statistique ou pourcentage
- Identifiez les sujets r√©currents et leur importance
- Ignorez compl√®tement les donn√©es non pertinentes au contexte

R√©ponse:""",

        "recommendations": f"""Contexte: {context}

Observations:
- Ratio contenus critiques/positifs dans les discussions
- Pr√©occupations principales identifi√©es

INSTRUCTION CRITIQUE:
R√©digez 2-4 paragraphes de recommandations strat√©giques bas√©es sur l'analyse.

R√àGLES STRICTES:
- R√©digez UNIQUEMENT en paragraphes fluides et coh√©rents
- N'utilisez JAMAIS de listes √† puces, num√©ros ou bullet points
- N'incluez AUCUN chiffre, statistique ou pourcentage
- Proposez des actions concr√®tes de mani√®re narrative
- Ton professionnel adapt√© √† un briefing minist√©riel

R√©ponse:"""
    }
    
    prompt = prompts.get(section_name, "")
    
    if not prompt:
        return f"[Section {section_name} non configur√©e]"
    
    try:
        # FORCER l'utilisation de Groq/Gemini en priorit√©
        services_to_try = []
        
        # 1. GROQ en premier (si disponible)
        if os.getenv("GROQ_API_KEY"):
            services_to_try.append(("groq", "llama-3.1-70b-versatile"))
            logger.info("üöÄ Tentative avec Groq (priorit√© 1)")
        
        # 2. GEMINI en second (si disponible)
        if os.getenv("GEMINI_API_KEY"):
            services_to_try.append(("gemini", "gemini-1.5-flash"))
            logger.info("üåü Gemini disponible en fallback (priorit√© 2)")
        
        # 3. OLLAMA en dernier recours uniquement
        services_to_try.append(("ollama", "gemma:2b"))
        
        # Essayer les services dans l'ordre de priorit√©
        last_error = None
        for service_name, model in services_to_try:
            try:
                logger.info(f"ü§ñ Tentative avec {service_name} ({model})...")
                
                response = await ai_service.generate_completion(
                    prompt=prompt,
                    max_tokens=800,
                    temperature=0.3,  # Factualit√© maximale
                    service=service_name,
                    model=model
                )
                
                if response and len(response.strip()) > 50:
                    logger.info(f"‚úÖ Section '{section_name}' g√©n√©r√©e avec {service_name}")
                    return response.strip()
                else:
                    logger.warning(f"‚ö†Ô∏è R√©ponse vide de {service_name}, passage au suivant")
                    
            except Exception as e:
                last_error = e
                logger.warning(f"‚ö†Ô∏è √âchec avec {service_name}: {str(e)}, passage au suivant")
                continue
        
        # Si tous les services ont √©chou√©
        raise Exception(f"Tous les services IA ont √©chou√©. Derni√®re erreur: {last_error}")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration section {section_name}: {str(e)}")
        return f"[Impossible de g√©n√©rer la section {section_name}]"


@router.post("/generate-narrative")
async def generate_narrative_report(
    keyword_ids: List[int] = Query(..., description="Liste des IDs de mots-cl√©s √† analyser"),
    period: str = Query("7d", description="P√©riode d'analyse (7d, 14d, 30d, 90d)"),
    sections: List[str] = Query(..., description="Sections √† inclure dans le rapport"),
    db: Session = Depends(get_db)
):
    """
    G√©n√®re un rapport intelligent narratif avec priorisation Groq/Gemini
    
    Sections disponibles:
    - summary: R√©sum√© ex√©cutif
    - sentiment: Analyse de sentiment
    - influencers: Influenceurs et acteurs cl√©s
    - themes: Th√®mes et pr√©occupations
    - recommendations: Recommandations strat√©giques
    """
    try:
        logger.info(f"üìä G√©n√©ration rapport narratif: keywords={keyword_ids}, period={period}")
        
        # === √âTAPE 1: R√©cup√©rer le contexte (mots-cl√©s) ===
        keywords = db.query(Keyword).filter(Keyword.id.in_(keyword_ids)).all()
        
        if not keywords:
            raise HTTPException(status_code=404, detail="Aucun mot-cl√© trouv√©")
        
        keyword_texts = [kw.keyword for kw in keywords]
        context = f"Surveillance de l'opinion publique sur : {', '.join(keyword_texts)}"
        
        logger.info(f"üéØ Contexte: {context}")
        
        # === √âTAPE 2: R√©cup√©rer les mentions de la p√©riode ===
        period_days = int(period.replace('d', ''))
        start_date = datetime.now() - timedelta(days=period_days)
        
        mentions = db.query(Mention).filter(
            Mention.keyword_id.in_(keyword_ids),
            Mention.collected_at >= start_date
        ).all()
        
        logger.info(f"üì• {len(mentions)} mentions collect√©es pour la p√©riode")
        
        if len(mentions) == 0:
            raise HTTPException(
                status_code=404,
                detail=f"Aucune mention trouv√©e pour la p√©riode de {period_days} jours"
            )
        
        # === √âTAPE 3: Filtrer les mentions pertinentes ===
        relevant_mentions = filter_relevant_content(mentions, keyword_texts)
        
        if len(relevant_mentions) == 0:
            raise HTTPException(
                status_code=404,
                detail="Aucun contenu pertinent trouv√© apr√®s filtrage"
            )
        
        # === √âTAPE 4: Initialiser le service IA (GROQ/GEMINI prioritaire) ===
        ai_service = get_prioritized_ai_service()
        available_services = ai_service.get_available_services()
        
        if not available_services:
            raise HTTPException(
                status_code=503,
                detail="Aucun service IA disponible"
            )
        
        # === √âTAPE 5: Pr√©parer les donn√©es pour chaque section ===
        # Limiter √† 50 mentions max pour √©viter surcharge
        sample_mentions = relevant_mentions[:50]
        
        data_summary = {
            "content": [
                {
                    "title": m.title or "Sans titre",
                    "source": m.source,
                    "author": m.author,
                    "excerpt": (m.content or "")[:300],
                    "sentiment": m.sentiment,
                    "collected_at": m.collected_at.isoformat() if m.collected_at else None
                }
                for m in sample_mentions[:10]  # 10 plus repr√©sentatives
            ]
        }
        
        data_sentiment = {
            "positive": [{"title": m.title, "excerpt": (m.content or "")[:200]} 
                        for m in sample_mentions if m.sentiment == "positive"][:5],
            "negative": [{"title": m.title, "excerpt": (m.content or "")[:200]} 
                        for m in sample_mentions if m.sentiment == "negative"][:5],
            "neutral": [{"title": m.title, "excerpt": (m.content or "")[:200]} 
                       for m in sample_mentions if m.sentiment == "neutral"][:5]
        }
        
        # Top auteurs par nombre de contenus
        from collections import Counter
        author_counts = Counter([m.author for m in sample_mentions if m.author])
        data_influencers = {
            "influencers": [
                {
                    "author": author,
                    "count": count,
                    "content": [
                        {"title": m.title, "source": m.source}
                        for m in sample_mentions if m.author == author
                    ][:3]
                }
                for author, count in author_counts.most_common(5)
            ]
        }
        
        # Trier par engagement pour identifier les th√®mes
        sorted_by_engagement = sorted(
            sample_mentions,
            key=lambda m: getattr(m, 'engagement_score', 0) or 0,
            reverse=True
        )
        
        data_themes = {
            "content": [
                {
                    "title": m.title,
                    "excerpt": (m.content or "")[:200],
                    "engagement": getattr(m, 'engagement_score', 0)
                }
                for m in sorted_by_engagement[:15]
            ]
        }
        
        # Donn√©es pour recommandations
        critical_ratio = len([m for m in sample_mentions if m.sentiment == "negative"]) / max(len(sample_mentions), 1)
        data_recommendations = {
            "critical_ratio": critical_ratio,
            "total_analyzed": len(sample_mentions),
            "main_concerns": [m.title for m in sorted_by_engagement[:5]]
        }
        
        # === √âTAPE 6: G√©n√©rer les sections demand√©es ===
        report_sections = {}
        
        section_data_map = {
            "summary": data_summary,
            "sentiment": data_sentiment,
            "influencers": data_influencers,
            "themes": data_themes,
            "recommendations": data_recommendations
        }
        
        for section in sections:
            if section in section_data_map:
                content = await generate_narrative_section(
                    ai_service,
                    section,
                    section_data_map[section],
                    context
                )
                report_sections[section] = content
        
        # === √âTAPE 7: Compiler le rapport final ===
        report = {
            "metadata": {
                "title": f"Rapport d'Analyse - {', '.join(keyword_texts)}",
                "generated_at": datetime.now().isoformat(),
                "period": f"{period_days} jours",
                "keywords": keyword_texts,
                "total_mentions_collected": len(mentions),
                "relevant_mentions_analyzed": len(relevant_mentions),
                "ai_services_used": available_services,
                "classification": "DOCUMENT DE TRAVAIL - DIFFUSION RESTREINTE"
            },
            "sections": report_sections,
            "context": context
        }
        
        logger.info(f"‚úÖ Rapport g√©n√©r√© avec succ√®s ({len(report_sections)} sections)")
        
        return report
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration rapport: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))