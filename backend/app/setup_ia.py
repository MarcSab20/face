#!/usr/bin/env python3
"""
Script de configuration automatique pour l'IA Souveraine
Installe et configure tous les composants n√©cessaires
"""

import os
import sys
import subprocess
import platform
import logging
import time
from pathlib import Path

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)


class IASetup:
    """Configuration automatique du syst√®me IA"""
    
    def __init__(self):
        self.system = platform.system()
        self.python_version = sys.version_info
        self.errors = []
        self.warnings = []
        
    def run_setup(self):
        """Lancer la configuration compl√®te"""
        logger.info("ü§ñ D√©but de la configuration de l'IA Souveraine")
        logger.info(f"Syst√®me: {self.system}, Python: {self.python_version.major}.{self.python_version.minor}")
        
        steps = [
            ("V√©rification des pr√©requis", self.check_prerequisites),
            ("Installation des d√©pendances Python", self.install_python_dependencies),
            ("Configuration d'Ollama", self.setup_ollama),
            ("T√©l√©chargement des mod√®les NLTK", self.setup_nltk),
            ("Configuration des mod√®les Spacy", self.setup_spacy),
            ("Test du service IA", self.test_ai_service),
            ("Configuration des variables d'environnement", self.setup_environment),
        ]
        
        for step_name, step_func in steps:
            logger.info(f"\nüìã {step_name}...")
            try:
                step_func()
                logger.info(f"‚úÖ {step_name} - Termin√©")
            except Exception as e:
                error_msg = f"‚ùå {step_name} - Erreur: {e}"
                logger.error(error_msg)
                self.errors.append(error_msg)
        
        self.print_summary()
    
    def check_prerequisites(self):
        """V√©rifier les pr√©requis syst√®me"""
        
        # V√©rifier Python 3.9+
        if self.python_version < (3, 9):
            raise Exception(f"Python 3.9+ requis, version d√©tect√©e: {self.python_version.major}.{self.python_version.minor}")
        
        # V√©rifier pip
        try:
            subprocess.run([sys.executable, "-m", "pip", "--version"], 
                         check=True, capture_output=True)
        except subprocess.CalledProcessError:
            raise Exception("pip n'est pas install√© ou accessible")
        
        # V√©rifier la m√©moire disponible
        import psutil
        memory_gb = psutil.virtual_memory().total / (1024**3)
        if memory_gb < 4:
            self.warnings.append(f"M√©moire faible ({memory_gb:.1f}GB). 8GB+ recommand√© pour l'IA")
        
        # V√©rifier CUDA (optionnel)
        try:
            import torch
            if torch.cuda.is_available():
                logger.info(f"üéÆ GPU CUDA d√©tect√©: {torch.cuda.get_device_name(0)}")
            else:
                self.warnings.append("GPU CUDA non d√©tect√© - performances CPU uniquement")
        except ImportError:
            logger.info("PyTorch pas encore install√© - v√©rification GPU plus tard")
        
        logger.info("Pr√©requis syst√®me OK")
    
    def install_python_dependencies(self):
        """Installer les d√©pendances Python"""
        
        requirements_files = [
            "requirements_ia.txt",  # D√©pendances IA sp√©cifiques
            "requirements.txt"      # D√©pendances g√©n√©rales
        ]
        
        for req_file in requirements_files:
            if os.path.exists(req_file):
                logger.info(f"Installation depuis {req_file}...")
                try:
                    subprocess.run([
                        sys.executable, "-m", "pip", "install", 
                        "-r", req_file, "--break-system-packages"
                    ], check=True, capture_output=True, text=True)
                except subprocess.CalledProcessError as e:
                    # Essayer sans --break-system-packages
                    subprocess.run([
                        sys.executable, "-m", "pip", "install", 
                        "-r", req_file
                    ], check=True)
            else:
                self.warnings.append(f"Fichier {req_file} non trouv√©")
        
        # Installation sp√©cifique PyTorch avec GPU si disponible
        self.install_pytorch()
    
    def install_pytorch(self):
        """Installer PyTorch avec support GPU si possible"""
        
        try:
            # D√©tecter CUDA
            nvidia_detect = subprocess.run(["nvidia-smi"], capture_output=True)
            cuda_available = nvidia_detect.returncode == 0
            
            if cuda_available:
                logger.info("üéÆ Installation PyTorch avec support CUDA...")
                subprocess.run([
                    sys.executable, "-m", "pip", "install",
                    "torch", "torchvision", "torchaudio",
                    "--index-url", "https://download.pytorch.org/whl/cu118"
                ], check=True)
            else:
                logger.info("üíª Installation PyTorch CPU uniquement...")
                subprocess.run([
                    sys.executable, "-m", "pip", "install",
                    "torch", "torchvision", "torchaudio", "--index-url",
                    "https://download.pytorch.org/whl/cpu"
                ], check=True)
                
        except subprocess.CalledProcessError:
            self.warnings.append("Installation PyTorch √©chou√©e - utilisation version par d√©faut")
    
    def setup_ollama(self):
        """Configurer Ollama pour les mod√®les LLM locaux"""
        
        # V√©rifier si Ollama est d√©j√† install√©
        try:
            result = subprocess.run(["ollama", "--version"], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                logger.info(f"Ollama d√©j√† install√©: {result.stdout.strip()}")
            else:
                raise subprocess.CalledProcessError(1, "ollama")
        except (subprocess.CalledProcessError, FileNotFoundError):
            # Installer Ollama
            self.install_ollama()
        
        # T√©l√©charger les mod√®les recommand√©s
        self.download_ollama_models()
    
    def install_ollama(self):
        """Installer Ollama selon le syst√®me"""
        
        if self.system == "Linux":
            logger.info("üì• Installation d'Ollama sur Linux...")
            subprocess.run([
                "curl", "-fsSL", "https://ollama.ai/install.sh"
            ], check=True, stdout=subprocess.PIPE)
            subprocess.run(["sh"], input=b"curl -fsSL https://ollama.ai/install.sh | sh", check=True)
            
        elif self.system == "Darwin":  # macOS
            logger.info("üì• Installation d'Ollama sur macOS...")
            subprocess.run([
                "curl", "-fsSL", "https://ollama.ai/install.sh"
            ], check=True, stdout=subprocess.PIPE)
            subprocess.run(["sh"], input=b"curl -fsSL https://ollama.ai/install.sh | sh", check=True)
            
        elif self.system == "Windows":
            logger.info("üì• Ollama sur Windows - installation manuelle requise")
            logger.info("T√©l√©chargez depuis: https://ollama.ai/download/windows")
            self.warnings.append("Installation manuelle d'Ollama requise sur Windows")
            return
        
        # Attendre qu'Ollama soit pr√™t
        time.sleep(5)
    
    def download_ollama_models(self):
        """T√©l√©charger les mod√®les Ollama recommand√©s"""
        
        models = [
            ("mistral:7b", "Mod√®le Mistral 7B (Recommand√©)"),
            ("llama2:7b", "Mod√®le Llama 2 7B"),
            ("neural-chat:7b", "Mod√®le Neural Chat 7B")
        ]
        
        for model_name, description in models:
            try:
                logger.info(f"üì¶ T√©l√©chargement {description}...")
                # Timeout long car les mod√®les sont volumineux
                subprocess.run(["ollama", "pull", model_name], 
                             check=True, timeout=1800)  # 30 minutes max
                logger.info(f"‚úÖ {description} t√©l√©charg√©")
            except subprocess.TimeoutExpired:
                self.warnings.append(f"Timeout t√©l√©chargement {model_name}")
            except subprocess.CalledProcessError:
                self.warnings.append(f"√âchec t√©l√©chargement {model_name}")
    
    def setup_nltk(self):
        """Configurer les donn√©es NLTK"""
        
        logger.info("üìö T√©l√©chargement des donn√©es NLTK...")
        
        try:
            import nltk
            
            # Dossier de donn√©es NLTK
            nltk_data_dir = os.path.expanduser("~/nltk_data")
            if not os.path.exists(nltk_data_dir):
                os.makedirs(nltk_data_dir)
            
            # T√©l√©charger les datasets n√©cessaires
            datasets = [
                'punkt',
                'stopwords', 
                'vader_lexicon',
                'averaged_perceptron_tagger',
                'wordnet'
            ]
            
            for dataset in datasets:
                try:
                    nltk.download(dataset, quiet=True)
                    logger.info(f"‚úÖ NLTK {dataset} t√©l√©charg√©")
                except Exception as e:
                    self.warnings.append(f"√âchec t√©l√©chargement NLTK {dataset}: {e}")
                    
        except ImportError:
            raise Exception("NLTK non install√© - v√©rifiez requirements_ia.txt")
    
    def setup_spacy(self):
        """Configurer les mod√®les Spacy"""
        
        logger.info("üß† Configuration des mod√®les Spacy...")
        
        models = [
            ("fr_core_news_sm", "Mod√®le fran√ßais l√©ger"),
            ("fr_core_news_md", "Mod√®le fran√ßais moyen (recommand√©)"),
            ("en_core_web_sm", "Mod√®le anglais l√©ger")
        ]
        
        for model_name, description in models:
            try:
                logger.info(f"üì¶ Installation {description}...")
                subprocess.run([
                    sys.executable, "-m", "spacy", "download", model_name
                ], check=True, capture_output=True)
                logger.info(f"‚úÖ {description} install√©")
            except subprocess.CalledProcessError:
                self.warnings.append(f"√âchec installation mod√®le Spacy {model_name}")
    
    def test_ai_service(self):
        """Tester que le service IA fonctionne"""
        
        logger.info("üß™ Test du service IA...")
        
        test_code = '''
import sys
import os
sys.path.append(os.getcwd())

try:
    from ia_service import SovereignLLMService
    
    # Initialiser le service
    llm_service = SovereignLLMService()
    
    # Tester la disponibilit√©
    if llm_service.is_available():
        print("‚úÖ Service IA disponible")
        
        if llm_service.ollama_available:
            print(f"‚úÖ Ollama actif avec {len(llm_service.available_models)} mod√®le(s)")
        
        if llm_service.transformers_available:
            print("‚úÖ HuggingFace Transformers actif")
        
        # Test d'analyse simple
        test_result = llm_service._analyze_with_rules(
            "test", 
            {"mentions": [{"title": "Test", "content": "Ceci est un test"}]}
        )
        print("‚úÖ Analyse de test r√©ussie")
        
    else:
        print("‚ùå Service IA non disponible")
        
except Exception as e:
    print(f"‚ùå Erreur test IA: {e}")
'''
        
        try:
            result = subprocess.run([
                sys.executable, "-c", test_code
            ], capture_output=True, text=True, cwd=os.getcwd())
            
            print(result.stdout)
            if result.stderr:
                print("STDERR:", result.stderr)
                
            if "Service IA disponible" in result.stdout:
                logger.info("‚úÖ Service IA op√©rationnel")
            else:
                self.warnings.append("Service IA partiellement fonctionnel")
                
        except Exception as e:
            self.warnings.append(f"Test IA √©chou√©: {e}")
    
    def setup_environment(self):
        """Configurer les variables d'environnement"""
        
        env_file = ".env"
        env_vars = {
            "AI_SERVICE_ENABLED": "true",
            "OLLAMA_HOST": "http://localhost:11434",
            "HF_HOME": os.path.expanduser("~/.cache/huggingface"),
            "TRANSFORMERS_CACHE": os.path.expanduser("~/.cache/huggingface/transformers"),
            "TORCH_HOME": os.path.expanduser("~/.cache/torch"),
        }
        
        # Lire le fichier .env existant
        existing_vars = {}
        if os.path.exists(env_file):
            with open(env_file, 'r') as f:
                for line in f:
                    if '=' in line and not line.startswith('#'):
                        key, value = line.strip().split('=', 1)
                        existing_vars[key] = value
        
        # Ajouter les nouvelles variables
        updated = False
        for key, value in env_vars.items():
            if key not in existing_vars:
                existing_vars[key] = value
                updated = True
        
        if updated:
            # R√©√©crire le fichier .env
            with open(env_file, 'w') as f:
                f.write("# Configuration automatique IA\n")
                for key, value in existing_vars.items():
                    f.write(f"{key}={value}\n")
            
            logger.info(f"Variables d'environnement ajout√©es √† {env_file}")
        else:
            logger.info("Variables d'environnement d√©j√† configur√©es")
    
    def print_summary(self):
        """Afficher le r√©sum√© de l'installation"""
        
        print("\n" + "="*60)
        print("ü§ñ R√âSUM√â DE LA CONFIGURATION IA SOUVERAINE")
        print("="*60)
        
        if not self.errors:
            print("‚úÖ Configuration termin√©e avec SUCC√àS!")
        else:
            print("‚ö†Ô∏è  Configuration termin√©e avec des ERREURS")
        
        if self.warnings:
            print(f"\n‚ö†Ô∏è  Avertissements ({len(self.warnings)}):")
            for warning in self.warnings:
                print(f"   ‚Ä¢ {warning}")
        
        if self.errors:
            print(f"\n‚ùå Erreurs ({len(self.errors)}):")
            for error in self.errors:
                print(f"   ‚Ä¢ {error}")
        
        print("\nüìã PROCHAINES √âTAPES:")
        print("   1. Red√©marrer votre terminal/IDE")
        print("   2. Tester l'API: python -m uvicorn app.main:app --reload")
        print("   3. Acc√©der √† l'interface: http://localhost:3000")
        print("   4. G√©n√©rer votre premier rapport IA dans la section Rapports")
        
        print("\nüîß COMMANDES UTILES:")
        print("   ‚Ä¢ Tester l'IA: python -c \"from ia_service import SovereignLLMService; print('IA:', SovereignLLMService().is_available())\"")
        print("   ‚Ä¢ Lister mod√®les Ollama: ollama list")
        print("   ‚Ä¢ Logs Ollama: ollama logs")
        
        print("\nüìö DOCUMENTATION:")
        print("   ‚Ä¢ Ollama: https://ollama.ai/docs")
        print("   ‚Ä¢ HuggingFace: https://huggingface.co/docs/transformers")
        print("   ‚Ä¢ Configuration IA: Voir ia_service.py")
        
        print("\nüöÄ Votre IA souveraine est pr√™te √† analyser!")
        print("="*60)


def main():
    """Point d'entr√©e principal"""
    
    if len(sys.argv) > 1 and sys.argv[1] in ['--help', '-h']:
        print("""
ü§ñ Script de Configuration IA Souveraine

Usage: python setup_ia.py [options]

Options:
  --help, -h     Afficher cette aide
  --check-only   V√©rifier uniquement les pr√©requis
  --no-models    Ne pas t√©l√©charger les mod√®les (plus rapide)

Ce script configure automatiquement:
  ‚úÖ D√©pendances Python pour l'IA
  ‚úÖ Ollama et mod√®les LLM locaux
  ‚úÖ Mod√®les NLTK et Spacy
  ‚úÖ Variables d'environnement
  ‚úÖ Test du service IA

Pr√©requis:
  ‚Ä¢ Python 3.9+
  ‚Ä¢ 8GB RAM recommand√©
  ‚Ä¢ Connexion Internet pour t√©l√©chargements
  ‚Ä¢ Droits administrateur (selon syst√®me)
        """)
        return
    
    setup = IASetup()
    
    if len(sys.argv) > 1 and sys.argv[1] == '--check-only':
        try:
            setup.check_prerequisites()
            print("‚úÖ Tous les pr√©requis sont satisfaits")
        except Exception as e:
            print(f"‚ùå Pr√©requis manquants: {e}")
        return
    
    setup.run_setup()


if __name__ == "__main__":
    main()