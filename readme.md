# Brand Monitor - SystÃ¨me de Surveillance des Mentions

# Brand Monitor v2.0 - SystÃ¨me Professionnel de Surveillance

> SystÃ¨me de surveillance et d'analyse d'opinion publique avec IA souveraine

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-Proprietary-red.svg)]()

## ğŸš€ CaractÃ©ristiques Principales

### Surveillance Multi-Sources
- **RÃ©seaux Sociaux**: YouTube, Reddit, TikTok, Telegram, Mastodon, Bluesky
- **MÃ©dias**: Google News, RSS Feeds, Web Scraping
- **Commentaires Complets**: RÃ©cupÃ©ration de tous les commentaires et threads

### Intelligence Artificielle Multi-Niveaux
**PrioritÃ© automatique des services IA:**
1. **Google Gemini** (prioritaire) - SynthÃ¨ses de haute qualitÃ©
2. **Groq** (secondaire) - RapiditÃ© et efficacitÃ©
3. **Ollama Local** (souverain) - Autonomie et confidentialitÃ©

### Analyses AvancÃ©es
- **RÃ©sumÃ© HiÃ©rarchique**: Traitement de milliers de contenus
- **DÃ©tection d'Anomalies**: Pics d'activitÃ©, changements de sentiment
- **Topic Modeling**: Extraction automatique des thÃ¨mes (BERTopic)
- **Analyse de RÃ©seau**: Cartographie des influenceurs et communautÃ©s

### Gestion des Influenceurs
- **Activistes SurveillÃ©s**: Liste prÃ©dÃ©finie avec profils dÃ©taillÃ©s
- **Influenceurs Ã‰mergents**: DÃ©tection automatique
- **MÃ©dias Officiels**: Suivi des sources institutionnelles

## ğŸ“‹ PrÃ©requis

### Obligatoires
- Python 3.11+
- PostgreSQL 15+
- Redis 7+
- Ollama (pour IA locale)

### RecommandÃ©s
- Docker & Docker Compose
- 8 GB RAM minimum
- 20 GB espace disque

## âš¡ Installation Rapide

### Option 1: Docker (RecommandÃ©)

```bash
# Cloner le projet
git clone <repo>
cd brand-monitor

# Copier et configurer .env
cp .env.example .env
nano .env  # Ajouter vos clÃ©s API

# DÃ©marrer tous les services
docker-compose up -d

# TÃ©lÃ©charger les modÃ¨les Ollama
docker exec brandmonitor_ollama ollama pull gemma:2b
docker exec brandmonitor_ollama ollama pull tinyllama
```

### Option 2: Installation Manuelle

```bash
# 1. Installer les dÃ©pendances
cd backend
pip install -r requirements.txt

# 2. TÃ©lÃ©charger les modÃ¨les NLP
python -m spacy download fr_core_news_sm
python -m spacy download en_core_web_sm
python -c "import nltk; nltk.download('vader_lexicon')"

# 3. Installer Ollama et tÃ©lÃ©charger les modÃ¨les
# Voir: https://ollama.ai/download
ollama pull gemma:2b
ollama pull tinyllama

# 4. Configuration
cp .env.example .env
nano .env  # Configurer les clÃ©s API

# 5. Initialisation
python backend/app/setup.py

# 6. DÃ©marrer le backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# 7. Servir le frontend (terminal sÃ©parÃ©)
cd frontend
python -m http.server 8080
```

## ğŸ”‘ Configuration des ClÃ©s API

### Services IA (RecommandÃ©s)

#### Google Gemini (Prioritaire)
**Gratuit**: 15 req/min, 1M tokens/mois
```bash
# 1. Aller sur https://makersuite.google.com/app/apikey
# 2. Se connecter et crÃ©er une clÃ©
# 3. Ajouter dans .env:
GEMINI_API_KEY=votre_cle_gemini
```

#### Groq (Secondaire)
**Gratuit**: 30 req/min
```bash
# 1. Aller sur https://console.groq.com
# 2. CrÃ©er un compte et une clÃ© API
# 3. Ajouter dans .env:
GROQ_API_KEY=votre_cle_groq
```

### Collecteurs (Optionnels)

#### YouTube
```bash
# Google Cloud Console > APIs > YouTube Data API v3
YOUTUBE_API_KEY=votre_cle_youtube
```

#### Reddit
```bash
# https://www.reddit.com/prefs/apps
REDDIT_CLIENT_ID=votre_client_id
REDDIT_CLIENT_SECRET=votre_secret
REDDIT_USER_AGENT=BrandMonitor/2.0
```

#### Google News
```bash
# https://gnews.io/ (100 req/jour gratuit)
GNEWS_API_KEY=votre_cle_gnews
```

## ğŸ¯ Utilisation

### AccÃ¨s Ã  l'Interface

- **Frontend**: http://localhost:8080
- **API Documentation**: http://localhost:8000/docs
- **API Alternative**: http://localhost:8000/redoc

### Workflow Typique

1. **CrÃ©er des Mots-clÃ©s**
   - Aller dans "Mots-clÃ©s"
   - Cliquer "Nouveau Mot-clÃ©"
   - SÃ©lectionner les sources
   
2. **Lancer une Collecte**
   - Vue "Mots-clÃ©s" > Bouton "Collecter"
   - Ou collecte automatique configurÃ©e

3. **Analyser les RÃ©sultats**
   - Dashboard: Vue d'ensemble
   - Mentions: DÃ©tails complets
   - Influenceurs: Profils et risques

4. **GÃ©nÃ©rer des Analyses IA**
   - Vue "Analyse IA"
   - RÃ©sumÃ© hiÃ©rarchique
   - DÃ©tection d'anomalies
   - Extraction de topics

5. **Exporter des Rapports**
   - Vue "Rapports"
   - SÃ©lectionner critÃ¨res
   - GÃ©nÃ©rer PDF

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚  Vue.js-like SPA (Vanilla JS)
â”‚   (Port 8080)   â”‚  Charts.js, Modern CSS
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ HTTP/REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend       â”‚  FastAPI + SQLAlchemy
â”‚   (Port 8000)   â”‚  Routes Advanced
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚     â”‚   Redis Cache    â”‚
â”‚   (Port 5432)   â”‚     â”‚   (Port 6379)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gemini API     â”‚ â†’   â”‚    Groq API      â”‚ â†’   â”‚  Ollama Local    â”‚
â”‚  (Prioritaire)  â”‚     â”‚  (Secondaire)    â”‚     â”‚  (Souverain)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Services IA - Ordre de PrioritÃ©

Le systÃ¨me utilise automatiquement les services dans cet ordre:

### 1. Google Gemini (Si configurÃ©)
- **ModÃ¨le**: gemini-1.5-flash
- **Avantages**: SynthÃ¨ses de trÃ¨s haute qualitÃ©, multilingue
- **Limites**: 15 req/min (gratuit)
- **Usage**: RÃ©sumÃ©s exÃ©cutifs, analyses complexes

### 2. Groq (Si configurÃ©)
- **ModÃ¨le**: llama-3.1-8b-instant
- **Avantages**: TrÃ¨s rapide, 30 req/min
- **Limites**: Textes plus courts
- **Usage**: Analyses rapides, classifications

### 3. Ollama Local (Toujours disponible)
- **ModÃ¨le**: gemma:2b (par dÃ©faut)
- **Avantages**: SouverainetÃ© totale, pas de limite, confidentialitÃ©
- **Limites**: Plus lent, qualitÃ© variable
- **Usage**: Fallback, analyses sensibles

**La prioritÃ© peut Ãªtre inversÃ©e** en mettant `USE_EXTERNAL_AI_PRIORITY=false` dans .env.

## ğŸ”’ SÃ©curitÃ© & ConfidentialitÃ©

### SouverainetÃ© des DonnÃ©es
- âœ… Ollama tourne localement (pas de fuite de donnÃ©es)
- âœ… Base de donnÃ©es locale
- âœ… Pas de dÃ©pendance obligatoire aux APIs externes

### Bonnes Pratiques
- Changer `SECRET_KEY` en production
- Utiliser HTTPS en production
- Configurer les CORS correctement
- Limiter l'accÃ¨s Ã  PostgreSQL
- Sauvegardes automatiques

## ğŸ“ˆ Performance

### CapacitÃ©s TestÃ©es
- **Collecte**: 10,000+ mentions/heure
- **Analyse**: 1,000+ contenus/minute (rÃ©sumÃ© hiÃ©rarchique)
- **Stockage**: Millions de mentions
- **Concurrence**: Plusieurs utilisateurs simultanÃ©s

### Optimisations
- Mise en cache Redis
- Traitement asynchrone
- Batch processing intelligent
- Indexation PostgreSQL

## ğŸ› DÃ©pannage

### Ollama ne rÃ©pond pas
```bash
# VÃ©rifier si Ollama tourne
curl http://localhost:11434/api/tags

# RedÃ©marrer Ollama
# Sur macOS/Linux:
ollama serve

# Docker:
docker restart brandmonitor_ollama
```

### Erreur de connexion PostgreSQL
```bash
# VÃ©rifier la connexion
docker exec -it brandmonitor_db psql -U brandmonitor -d brandmonitor

# RecrÃ©er la base
docker-compose down -v
docker-compose up -d
```

### Services IA tous indisponibles
```bash
# Tester chaque service
curl http://localhost:8000/api/advanced/ai/health

# VÃ©rifier les logs
docker-compose logs backend
```

## ğŸ“š Documentation API

### Endpoints Principaux

#### Mots-clÃ©s
- `GET /api/keywords` - Liste des mots-clÃ©s
- `POST /api/keywords` - CrÃ©er un mot-clÃ©
- `DELETE /api/keywords/{id}` - Supprimer

#### Mentions
- `GET /api/mentions` - Liste avec filtres
- `GET /api/mentions/{id}` - DÃ©tails

#### Collecte
- `POST /api/collect` - Lancer une collecte
- `POST /api/analyze-sentiment/{id}` - Analyser le sentiment

#### Analyse AvancÃ©e
- `POST /api/advanced/summarize` - RÃ©sumÃ© hiÃ©rarchique
- `GET /api/advanced/influencers` - Analyse des influenceurs
- `GET /api/advanced/anomalies` - DÃ©tection d'anomalies
- `GET /api/advanced/topics` - Extraction de topics
- `GET /api/advanced/network` - RÃ©seau d'influence

#### IA
- `GET /api/advanced/ai/health` - SantÃ© des services IA
- `POST /api/advanced/ai/test` - Tester la gÃ©nÃ©ration

## ğŸ¤ Support & Contribution

### Rapporter un Bug
CrÃ©er une issue avec:
- Description du problÃ¨me
- Ã‰tapes pour reproduire
- Logs pertinents
- Configuration (sans clÃ©s API!)

### DÃ©veloppement
```bash
# Backend
cd backend
pip install -r requirements.txt
pytest  # Tests

# Frontend
cd frontend
# Pas de build nÃ©cessaire (vanilla JS)
```

## ğŸ“ Licence

PropriÃ©taire - Tous droits rÃ©servÃ©s

## ğŸ“ CrÃ©dits

- **FastAPI** - Framework web
- **Ollama** - IA locale souveraine
- **BERTopic** - Topic modeling
- **Chart.js** - Visualisations
- **spaCy & NLTK** - NLP

---

**Version**: 2.0.0  
**DerniÃ¨re mise Ã  jour**: DÃ©cembre 2024  
**Support**: [Contact]